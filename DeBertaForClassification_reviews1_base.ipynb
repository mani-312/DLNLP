{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e02b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "#from torchmetrics import Accuracy, F1Score\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "RAW_DATASET_DIR = \"raw_datasets/SST_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ded53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0e99a",
   "metadata": {},
   "source": [
    "### Word piece tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14f3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_model_name = \"microsoft/deberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc1be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaTokenizer\n",
    "tokenizer = DebertaTokenizer.from_pretrained(deberta_model_name)\n",
    "\n",
    "sequence = \"Hello, my dog is cute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9017fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'Ġmy', 'Ġdog', 'Ġis', 'Ġcute']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sequence = tokenizer.tokenize(sequence)\n",
    "print(tokenized_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3b227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 31414, 6, 127, 2335, 16, 11962, 2]\n"
     ]
    }
   ],
   "source": [
    "encoded_sequence = tokenizer(sequence)[\"input_ids\"]\n",
    "print(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0353c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]Hello, my dog is cute[SEP]\n"
     ]
    }
   ],
   "source": [
    "decoded_sequence = tokenizer.decode(encoded_sequence)\n",
    "print(decoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c009c",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2044d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12256</th>\n",
       "      <td>work was being carried out which we weren t aware of the rooms were tiny very little space to get around the bed and the beds were small our feet hung over the edge despite having booked a deluxe room there was no decent public space to relax in either the theatre was freezing and the lobby was unappealing despite the lovely photos the cleanliness of the room was poor very dusty lots of marks on the walls and floor and the sheets had not been changed since the last guests the staff did try their best including moving rooms as the heater was making a noise in the first room but the move itself was very shambolic they did apologise and gave us complementary chocolates and wine but we shall not stay here again when there are lots of other lovely hotels in the same area for the same price</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>4 start hotel should do more than a poor service every thing is chargeable even water the size of the room is so small and the design is very strange can not understand it the matters and pillow is very poor quality and had strong headaches every day morning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9007</th>\n",
       "      <td>room was very small and the bed seemed to still be dirty after it had been cleaned</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9648</th>\n",
       "      <td>the beds were comfy facilities in the room were good room service was excellent very delicious and quick central location</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>sofa bed uncomfortable for children short wait for a table at breakfast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review  \\\n",
       "12256   work was being carried out which we weren t aware of the rooms were tiny very little space to get around the bed and the beds were small our feet hung over the edge despite having booked a deluxe room there was no decent public space to relax in either the theatre was freezing and the lobby was unappealing despite the lovely photos the cleanliness of the room was poor very dusty lots of marks on the walls and floor and the sheets had not been changed since the last guests the staff did try their best including moving rooms as the heater was making a noise in the first room but the move itself was very shambolic they did apologise and gave us complementary chocolates and wine but we shall not stay here again when there are lots of other lovely hotels in the same area for the same price    \n",
       "6406                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              4 start hotel should do more than a poor service every thing is chargeable even water the size of the room is so small and the design is very strange can not understand it the matters and pillow is very poor quality and had strong headaches every day morning   \n",
       "9007                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             room was very small and the bed seemed to still be dirty after it had been cleaned    \n",
       "9648                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      the beds were comfy facilities in the room were good room service was excellent very delicious and quick central location    \n",
       "15640                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       sofa bed uncomfortable for children short wait for a table at breakfast    \n",
       "\n",
       "       sentiment  \n",
       "12256          0  \n",
       "6406           0  \n",
       "9007           0  \n",
       "9648           1  \n",
       "15640          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun1(review):\n",
    "    review = review.lower() # lowercase, standardize\n",
    "    return review\n",
    "\n",
    "def fun2(x):\n",
    "    if x=='negative':\n",
    "        return 0\n",
    "    elif x=='positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Classification0,2 are imbalanced\n",
    "\n",
    "#df = pd.read_excel('ClassificationDataset2.xlsx',names = ['sentiment','review']) # classification2\n",
    "#df = pd.read_excel('ClassificationDataset0.xlsx',names=['sentiment','review'],header = None) #Classification0\n",
    "#df = pd.read_csv('all-data.csv',encoding=\"ISO-8859-1\",names=['sentiment','review'],header = None) # all-data\n",
    "df = pd.read_csv('ClassificationDataset1_new.csv') # ../../Sentiment_classification(Movie_reviews)/train.csv, Classification1_new.csv\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "df = df.dropna()\n",
    "df = df.sample(frac=1) # shuffles the data\n",
    "\n",
    "# get rid of punctuation\n",
    "df['review'] = df['review'].apply(fun1)\n",
    "#df['sentiment'] = df['sentiment'].apply(fun2)  # Classification0,all_data\n",
    "#df['sentiment'] = df['sentiment'].apply(lambda x: x-1) # classification2\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744c54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeBertaDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer,n_folds = 1,leave_out_fold = 0,split = 'train', max_length_sentence=100):\n",
    "        super(DeBertaDataset, self).__init__()\n",
    "\n",
    "        texts = list(df['review'].values)\n",
    "        labels = list(df['sentiment'].values)\n",
    "        \n",
    "        if n_folds == 1:\n",
    "            # 80-20 split\n",
    "            if split == 'train':\n",
    "                X,Y = texts[:int(len(texts)*0.8)], labels[:int(len(texts)*0.8)]\n",
    "            else:\n",
    "                X,Y = texts[int(len(texts)*0.8):], labels[int(len(texts)*0.8):]\n",
    "        else:\n",
    "            each_fold = int(len(texts)/n_folds) \n",
    "            if split == 'train':\n",
    "                print(leave_out_fold*each_fold)\n",
    "                X_l,Y_l = texts[: leave_out_fold*each_fold ], labels[: leave_out_fold*each_fold ]\n",
    "                X_r,Y_r = texts[(leave_out_fold+1)*each_fold:], labels[(leave_out_fold+1)*each_fold :]\n",
    "                X_l.extend(X_r)\n",
    "                Y_l.extend(Y_r)\n",
    "                X = X_l\n",
    "                Y = Y_l\n",
    "            else:\n",
    "                X,Y = texts[leave_out_fold*each_fold: (leave_out_fold+1)*each_fold ], labels[leave_out_fold*each_fold : (leave_out_fold+1)*each_fold ]\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.tokenizer=tokenizer\n",
    "        self.max_length = max_length_sentence\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text1 = self.X[index]\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text1 ,\n",
    "            None, # since we have only 1 sentence as input\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long).to(device),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long).to(device),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long).to(device),\n",
    "            'target': torch.tensor(self.Y[index], dtype=torch.long).to(device)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42aebab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size ==  14398\n",
      "Val data size ==  3600\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DeBertaDataset(df,tokenizer,split='train')\n",
    "test_dataset = DeBertaDataset(df,tokenizer,split='val')\n",
    "\n",
    "print(\"Train data size == \",len(train_dataset))\n",
    "print(\"Val data size == \",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff73c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247280cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manikanta/miniconda3/envs/score/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2383: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[   1,    5, 3267,  ...,    0,    0,    0],\n",
       "         [   1,  115,   33,  ...,    0,    0,    0],\n",
       "         [   1, 2579, 2382,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,  182, 2579,  ...,    0,    0,    0],\n",
       "         [   1, 2362, 2430,  ...,    0,    0,    0],\n",
       "         [   1,    5, 7676,  ...,    0,    0,    0]], device='cuda:0'),\n",
       " 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'target': tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "         1, 0, 1, 0, 0, 1, 0, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data loaders\n",
    "dict = next(iter(train_dataloader))\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44a0675f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] breakfast facilities were overcrowded[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dict['ids'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52968a",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77cdefd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 100, 437, 3645, 112, 2, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = tokenizer.encode_plus(\n",
    "            \"I'm sentence 1\", # text\n",
    "            None, # text pair\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=True,\n",
    "            max_length=10,\n",
    "        )\n",
    "op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fddc30f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ef50fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DebertaForSequenceClassification\n",
    "\n",
    "model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\",num_labels = NUM_CLASSES).to(device)\n",
    "lr = 5e-5\n",
    "optimizer= optim.Adam(model.parameters(),lr= lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "014b065e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/450 [00:00<?, ?it/s]                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :0 = 0.9319349909709682\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/450 [00:00<?, ?it/s]                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :1 = 0.9640922350326434\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :2 = 0.9722183636616196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loop=tqdm(enumerate(train_dataloader),leave=False,total=len(train_dataloader))\n",
    "    print(epoch)\n",
    "    total_matches = 0\n",
    "    for batch, dl in loop:\n",
    "        \n",
    "        # input\n",
    "        ids, token_type_ids, mask, label = dl['ids'], dl['token_type_ids'], dl['mask'], dl['target']\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        output = model(ids,mask,token_type_ids, labels=label)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss)\n",
    "        logits = output.logits\n",
    "        pred = logits.argmax(dim=1)\n",
    "        \n",
    "        # prediction\n",
    "        matches = (torch.sum(pred == label)).item()\n",
    "        accuracy = matches/BATCH_SIZE\n",
    "        total_matches += matches\n",
    "\n",
    "        # Show progress while training\n",
    "        loop.set_description_str(f\"Epoch={epoch}/{epochs} loss={loss.item()} accuracy={accuracy}\")\n",
    "\n",
    "    \n",
    "    print(f\"Train Accuracy :{epoch} = {total_matches/len(train_dataset)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55dde614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_name = f\"DeBERTaForClassification_reviews0_{epochs}_{lr}_FULL.pt\"\n",
    "torch.save(model.state_dict(), f\"{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8480667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('DeBERTaForClassification_reviews1_3_5e-05_FULL.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860a6b8",
   "metadata": {},
   "source": [
    "## Tesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f419e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/113 [00:00<?, ?it/s]/home/manikanta/miniconda3/envs/score/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2383: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy :0.9755555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "test_losses = []\n",
    "total_correct = []\n",
    "total_pred = []\n",
    "\n",
    "model.eval()\n",
    "loop=tqdm(enumerate(test_dataloader),leave=False,total=len(test_dataloader))\n",
    "total_matches = 0\n",
    "with torch.no_grad():\n",
    "    for batch, dl in loop:\n",
    "        ids, token_type_ids, mask, label = dl['ids'], dl['token_type_ids'], dl['mask'], dl['target']\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(ids,mask,token_type_ids, labels=label)\n",
    "        loss = output.loss\n",
    "\n",
    "        logits = output.logits\n",
    "        pred = logits.argmax(dim=1)\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        matches = torch.sum(pred == label)\n",
    "        total_pred.extend(list(pred.cpu().numpy()))\n",
    "        total_correct.extend(list(label.cpu().numpy()))\n",
    "        total_matches += matches.item()\n",
    "\n",
    "        # Show progress while training\n",
    "        loop.set_description(f'loss={loss.item()}')\n",
    "\n",
    "\n",
    "    print(f\"Test Accuracy :{total_matches/len(test_dataset)}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63a79fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1744\n",
      "           1       0.98      0.97      0.98      1856\n",
      "\n",
      "    accuracy                           0.98      3600\n",
      "   macro avg       0.98      0.98      0.98      3600\n",
      "weighted avg       0.98      0.98      0.98      3600\n",
      "\n",
      "\n",
      "------------- Micro F1 Score == 0.9755555555555555 ------------\n",
      "------------- Macro F1 Score == 0.9755388782043066 ------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(classification_report(total_correct, total_pred))\n",
    "\n",
    "macroF1 = f1_score(total_correct, total_pred, average='macro')\n",
    "microF1 = f1_score(total_correct, total_pred, average='micro')\n",
    "\n",
    "print(\"\\n------------- Micro F1 Score == {} ------------\".format(microF1))\n",
    "print(\"------------- Macro F1 Score == {} ------------\\n\".format(macroF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d113c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
